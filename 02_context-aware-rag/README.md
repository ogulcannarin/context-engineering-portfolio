Context-Aware RAG PDF Assistant

A context-aware Retrieval-Augmented Generation (RAG) system that intelligently processes retrieved context before sending it to an LLM, improving answer relevance and reducing hallucinations.

This project demonstrates practical context engineering techniques such as filtering, ranking, token optimization, and summarization.

ğŸ¯ Project Goal

Most RAG systems simply retrieve chunks and send them to the LLM.

This project focuses on:

Optimizing context before generation

to improve accuracy, efficiency, and reliability.
Features

âœ… PDF document ingestion
âœ… Smart chunking with overlap
âœ… Embedding-based semantic search
âœ… Vector database retrieval (ChromaDB)
âœ… Context filtering
âœ… Relevance ranking
âœ… Token budgeting
âœ… Context summarization
âœ… Hallucination reduction prompt strategy

PDF â†’ Chunking â†’ Embeddings â†’ Vector DB
                              â†“
User Query â†’ Retrieval
                              â†“
Filtering â†’ Ranking â†’ Token Control â†’ Summarization
                              â†“
LLM â†’ Final Answer

Why This Project Matters

Many RAG demos stop at retrieval.

This project goes further by implementing context processing pipelines, which are critical in production-grade RAG systems.

It shows understanding of:

Context engineering

LLM limitations

Token efficiency

Hallucination mitigation

Retrieval optimization

ğŸ› ï¸ Tech Stack

Python

LangChain

OpenAI API

ChromaDB

PyPDF

dotenv

âš™ï¸ Installation
1ï¸âƒ£ Clone the repo
git clone https://github.com/yourusername/context-aware-rag.git
cd context-aware-rag

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Set API key

Create .env file:

OPENAI_API_KEY=your_api_key_here

4ï¸âƒ£ Add PDF

Place your PDF in:

data/sample.pdf

5ï¸âƒ£ Run
python app.py

ğŸ’¡ Example Use Cases

Research paper Q&A

Study assistant

Document analysis

Contract review

Knowledge base assistant

ğŸ“ˆ Future Improvements

Source citation

Cross-encoder reranking

Multi-query retrieval

Web UI (Streamlit/Gradio)

Persistent vector storage

Memory-aware conversations

ğŸ§‘â€ğŸ’» Author

OÄŸulcan Narin
Software Engineering Student 

